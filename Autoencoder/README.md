# Autoencoder
## Definition
They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation. This kind of network is composed of two parts :


- Encoder: This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function $h=f(x)$.


- Decoder: This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function $r=g(h)$.

![alt text](https://miro.medium.com/max/1400/1*V_YtxTFUqDrmmu2JqMZ-rA.png)

* Similar technique: PCA
https://en.wikipedia.org/wiki/Low-rank_approximation#:~:text=In%20mathematics%2C%20low%2Drank%20approximation,approximating%20matrix%20has%20reduced%20rank
https://www.upgrad.com/blog/neural-network-project-ideas-topics-beginners/
